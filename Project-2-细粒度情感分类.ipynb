{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hint(string): return print(''.join(map(chr, map(lambda x: int(x, 16), string.split('.')))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一部分 背景与问题描述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "+ jupyter notebook (测试、试验环境)\n",
    "+ Pycharm （开发环境）\n",
    "+ python3.6\n",
    "+ networkx\n",
    "+ jieba\n",
    "+ numpy, pandas, matplotlib\n",
    "+ gensim\n",
    "+ (optional) bottle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在自然语言处理中，有一个常见的问题就是对客户的评价进行分析。 这些用户评论中，包含了大量的有用信息，例如情感分析，或者相关事实描述。 例如，\n",
    "> `“味道不错的面馆，性价比也相当之高，分量很足～女生吃小份，胃口小的，可能吃不完呢。环境在面馆来说算是好的，至少看上去堂子很亮，也比较干净，一般苍蝇馆子还是比不上这个卫生状况的。中午饭点的时候，人很多，人行道上也是要坐满的，隔壁的冒菜馆子，据说是一家，有时候也会开放出来坐吃面的人。“`\n",
    "\n",
    "首先情感是正向的，除此之外我们还能够进行知道这个的几个事实描述：1. 性价比比较高； 2. 装修比较好； 3. 分量足。 \n",
    "\n",
    "这些信息是非常重要宝贵的，不论是对于公司进行商业分析或者要建立一个搜索引擎排序，这些信息都是重要的参考因素。 那么在这个时候，我们就需要进行文本的情感分类了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注**: 此次问题的来源数据集来源于大众点评， 这个数据集也被用作 AI 全球挑战赛的数据集。 而且细粒度情感分类这个问题其实在目前而言是一个 *未解之谜*， 人类现在对这个问题并没有什么特别好的方法， 因为人的情感表达真的是很有变化的，例如“我不认为这个地方不好是不对的”。所以这个问题也需要大家在之后做出来基础模型之后，大家多想想办法，*八仙过海，各显神通*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以，我们这一次是要使用深度学习的方法，建立一个模型，这个模型能够将一句话进行分类判断，判断出来这句话到底表达了什么重要信息。 说实话，这个看似简单的问题，曾经是困扰了科学家数十年的问题，就算是现在，深度学习，人工智能有了很大的进步，其效果也达不到人们预期的那么好,但是比起前些年已经好多了:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个问题我们希望的是，输入一句话，输出是这句话对于以下6大类，20小类进行打标，对于每个小类而言，都会有<** 正面情感, 中性情感, 负面情感, 情感倾向未提及 > ** 这4个类别。 \n",
    "\n",
    "总得来说，我们现在这6大类，20小类的类别如下：\n",
    "\n",
    "+ 位置: location\n",
    "    + 交通是否便利(traffic convenience)\n",
    "    + 距离商圈远近(distance from business district)\n",
    "    + 是否容易寻找(easy to find)\n",
    "+ 服务(service)\t\n",
    "    + 排队等候时间(wait time)\n",
    "    + 服务人员态度(waiter’s attitude)\n",
    "    + 是否容易停车(parking convenience)\n",
    "    + 点菜/上菜速度(serving speed)\n",
    "+ 价格(price)\t\n",
    "    + 价格水平(price level)\n",
    "    + 性价比(cost-effective)\n",
    "    + 折扣力度(discount)\n",
    "+ 环境(environment)\t\n",
    "    + 装修情况(decoration)\n",
    "    + 嘈杂情况(noise)\n",
    "    + 就餐空间(space)\n",
    "    + 卫生情况(cleaness)\n",
    "+ 菜品(dish)\t\n",
    "    + 分量(portion)\n",
    "    + 口感(taste)\n",
    "    + 外观(look)\n",
    "    + 推荐程度(recommendation)\n",
    "+ 其他(others)\t\n",
    "    + 本次消费感受(overall experience)\n",
    "    + 再次消费的意愿(willing to consume again)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而为了方便训练数据的标标注，训练数据中，<** 正面情感, 中性情感, 负面情感, 情感倾向未提及 > ** 分别对应与 (1, 0, -1, -2). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例如说，\n",
    "> `“味道不错的面馆，性价比也相当之高，分量很足～女生吃小份，胃口小的，可能吃不完呢。环境在面馆来说算是好的，至少看上去堂子很亮，也比较干净，一般苍蝇馆子还是比不上这个卫生状况的。中午饭点的时候，人很多，人行道上也是要坐满的，隔壁的冒菜馆子，据说是一家，有时候也会开放出来坐吃面的人。“`\n",
    "\n",
    "这句话在训练数据中的标签就是：\n",
    "\n",
    "+ 交通是否便利(traffic convenience)\t-2 \n",
    "+ 距离商圈远近(distance from business district)\t-2\n",
    "+ 是否容易寻找(easy to find)\t-2\n",
    "+ 排队等候时间(wait time)\t-2\n",
    "+ 服务人员态度(waiter’s attitude)\t-2\n",
    "+ 是否容易停车(parking convenience)\t-2\n",
    "+ 点菜/上菜速度(serving speed)\t-2\n",
    "+ 价格水平(price level)\t-2\n",
    "+ 性价比(cost-effective)\t1\n",
    "+ 折扣力度(discount)\t-2\n",
    "+ 装修情况(decoration)\t1\n",
    "+ 嘈杂情况(noise)\t-2\n",
    "+ 就餐空间(space)\t-2\n",
    "+ 卫生情况(cleaness)\t1\n",
    "+ 分量(portion)\t1\n",
    "+ 口感(taste)\t1\n",
    "+ 外观(look)\t-2\n",
    "+ 推荐程度(recommendation)\t-2\n",
    "+ 次消费感受(overall experience)\t1\n",
    "+ 再次消费的意愿(willing to consume again)\t-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集下载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集的下载在 https://challenger.ai/competition/fsauor2018， 大家下载数据集， 以及测试集，注意，训练集我们需要分成 training data, validation data 然后 test data里边的数据绝对不能在训练的时候用。 否则的话就是去了意义。 \n",
    "\n",
    "**注**, 这个数据集之所以被用到了 AI 挑战赛中，是因为其难度很大。 绝大数人在公司中遇到的问题难度**不会**超过这个问题。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评价\n",
    "\n",
    "参照 https://challenger.ai/competition/fsauor2018, 这个问题的评价其实就是多个分类的f1 score 的平均值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二部分 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: 机器学习中的Loss函数的作用为何？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the # before hint, what you find? \n",
    "#hint('8fd9.4e2a.7b54.6848.53ef.4ee5.5199.5f88.591a.ff0c.4f46.662f.4e3b.8981.662f.8981.6d89.53ca.5230.ff1a.4c.6f.73.73.20.51fd.6570.7528.6765.8861.91cf.673a.5668.5b66.4e60.8fc7.7a0b.4e2d.6a21.578b.8868.73b0.7684.ff0c.6211.4eec.901a.8fc7.20.4c.6f.73.73.20.51fd.6570.6765.8fdb.884c.4f18.5316.6a21.578b.6216.8005.9009.62e9.6a21.578b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Q2: 为什么 SVM 适合核函数的方法？（考虑基于拉格朗日距离的 SVM 的 Loss 函数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint('8be6.60c5.8bf7.53c2.8003.6211.4eec.7684.8bfe.7a0b.89c6.9891.ff0c.4e00.4e2a.4e3b.8981.7684.70b9.662f.ff0c.6700.540e.8bc1.660e.20.53.56.4d.20.6a21.578b.7684.6027.80fd.53ea.4e0e.20.78.5f.69.78.5f.6a.20.7684.4e58.673a.76f8.5173.ff0c.6240.4ee5.6211.4eec.53ef.4ee5.65b9.4fbf.7684.628a.78.5f.69.20.78.5f.6a.20.6620.5c04.5230.67d0.4e2a.65b0.51fd.6570.4e0a.ff0c.4e0d.6539.53d8.5176.20.4c.6f.73.73.20.7684.5355.8c03.6027.5373.53ef')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: 决策树的 Loss 函数是什么？随机森林是什么？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint(\"\"\"4e00.3001.71b5.7684.548c.6700.5c0f.ff0c.8981.9009.62e9.4e00.4e2a.6761.4ef6.8ba9.8fd9.6b21.5206.7c7b.7684.4e24.8fb9.7ed3.679c.7adf.53ef.80fd.7684.2018.7eaf.2019.2c.20.4f8b.5982.ff0c.6211.4eec.6709.5b.32.2c.20.31.2c.20.30.2c.20.30.2c.20.30.2c.20.30.2c.20.31.2c.20.31.2c.20.31.2c.20.31.2c.20.31.5d.a.5982.679c.6211.4eec.9009.62e9.4e00.4e2a.6761.4ef6.662f.27.662f.4e0d.662f.31.27.ff0c.6211.4eec.53ef.4ee5.5206.6210.5b.30.2c.20.30.2c.20.30.2c.20.30.2c.20.32.5d.2c.20.5b.31.2c.20.31.2c.20.31.2c.20.31.2c.20.31.5d.ff0c.20.4e5f.53ef.4ee5.6761.4ef6.662f.27.662f.4e0d.662f.32.27.2c.20.a.6211.4eec.5c31.53ef.4ee5.5206.6210.5b.32.5d.2c.20.5b.31.2c.20.30.2c.20.30.2c.20.30.2c.20.30.2c.20.31.2c.20.31.2c.20.31.2c.20.31.2c.20.31.5d.ff0c.20.663e.7136.524d.8005.66f4.7eaf.3002.20.5982.679c.540c.5b66.4eec.5fd8.4e86.71b5.7684.6982.5ff5.ff0c.5927.5bb6.8d76.7d27.518d.67e5.4e00.4e0b.ff0c.7136.540e.8ba1.7b97.4e00.4e0b.8fd9.4e24.4e2a.5206.7c7b.7ed3.679c.7684.71b5.662f.591a.5927.ff1b.a.4e8c.3001.968f.673a.68ee.6797.662f.7528.5f88.591a.5c0f.7684.51b3.7b56.6811.7528.6765.6295.7968.7684.96c6.6210.6a21.578b.ff08.45.6e.73.65.6d.62.6c.65.ff09.ff0c.6bcf.4e2a.5c0f.51b3.7b56.6811.4f7f.7528.4e00.90e8.5206.7684.20.66.65.61.74.75.72.65.20.8fdb.884c.8bad.7ec3\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**插入**：我们在这里快速的过一下如何在 Jupyter 中写数学公式。 这个其实很简单，如果我们要输入一个公式，例如A1, 那么，我们在Jupyter中输入`$A_i$`, 然后 Enter， 是不是就变成了$A_i$? 其实两个`$$`之间的东西就是 Latex 的符号，`$..$`这个我们叫做inline模式，意思就是说你写出来的公式是和你的文字在一行里，如果你`$$..$$``，这个公式就会单独是一行。\n",
    "\n",
    "我们现在再试一个, 输入`$$\\frac{P_i}{\\sum_{j \\in \\mathbf{V}}^NP_j}$$`, 输完之后 Enter， 你看到了什么？ \n",
    "\n",
    "$$\\frac{P_i}{\\sum_{j \\in \\mathbf{V}}^NP_j}$$\n",
    "\n",
    "这个时候会有同学说，可是这些符号，我怎么记得住呢？ 我给大家提供了一个参考手册，大家有空就看看 https://github.com/Artificial-Intelligence-for-NLP/comment-setimental-classification/blob/master/Latex-Symbols.pdf，熟能生巧。 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4: 使用Latex 写出来决策树希望找到一个 feature，这个 feature 使得熵的和最少的公式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q5: 贝叶斯公式的原理是什么？ 我们现在用的贝叶斯分类器为什么是“朴素贝叶斯”， 它为什么朴素？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6: 神经网络的Loss函数的作用为何？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint(\"\"\"795e.7ecf.7f51.7edc.91cc.9762.7684.4c.6f.73.73.51fd.6570.662f.7528.6765.8861.91cf.6a21.578b.7684.597d.574f.ff0c.4c.6f.73.73.51fd.6570.8d8a.5927.ff0c.9884.6d4b.4e0e.5b9e.9645.7684.8bef.5dee.8d8a.5927.ff0c.9884.6d4b.8d8a.4e0d.51c6.786e.3002.4e3a.4e86.8ba9.9884.6d4b.7ed3.679c.66f4.52a0.7cbe.51c6.ff0c.6211.4eec.8981.51cf.5c11.4c.6f.73.73.51fd.6570.ff0c.901a.8fc7.68af.5ea6.4e0b.964d.6cd5.ff0c.5229.7528.53cd.5411.4f20.64ad.4e0d.505c.8fed.4ee3.8c03.6574.795e.7ecf.7f51.7edc.4e2d.7684.53c2.6570.ff0c.627e.5230.4f7f.4c.6f.73.73.51fd.6570.6700.5c0f.7684.53c2.6570.ff0c.786e.5b9a.6a21.578b.3002\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7: 神经网络的激活函数(activation function)起什么作用？ 如果没有激活函数会怎么样？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint('6fc0.6d3b.51fd.6570.7528.6765.8fdb.884c.975e.7ebf.6027.53d8.5316.ff0c.4e0d.65ad.5f97.975e.7ebf.6027.53d8.5316.4f7f.5f97.6211.4eec.28.7406.8bba.4e0a.29.53ef.4ee5.62df.5408.4efb.610f.51fd.6570.ff0c.8fd9.4e5f.662f.4e3a.4ec0.4e48.795e.7ecf.7f51.7edc.80fd.60.5b66.4e60.60.7684.539f.56e0.3002.795e.7ecf.7f51.7edc.91cc.8fb9.7684.60.5b66.4e60.60.5176.5b9e.5c31.662f.51fd.6570.62df.5408.7684.610f.601d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8: 神经网络的softmax如何理解， 其作用是什么？ 在`答案`中写出softmax的python表达；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9: 简述 normalized_1 和softmax函数的相同点和不同点， 说明softmax相比normalized_1该函数的优势所在"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "output = np.array([y1, y2, y3])\n",
    "\n",
    "normalized_1 = output / np.sum(output)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10: 写出crossentropy的函数表达式，说明该函数的作用和意义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------- 休息一下，接下来是关于 Word2Vec的 ------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q11: 说明word2vec要解决的问题背景， 以及word2vec的基本思路， 说明word2vec比起之前方法的优势；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q12: 说明word2vec的预测目标， predication target, 在答案中写出skip-gram和cbow的预测概率；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q13: 请说明word2vec的两种常见优化方法，分别阐述其原理；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q14: 请说明word2vec中哈夫曼树的作用；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q15: 哈夫曼树如何构建？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint('a.31.2e.20.68.74.74.70.73.3a.2f.2f.67.69.74.68.75.62.2e.63.6f.6d.2f.68.65.69.6e.65.6d.61.6e.2f.70.79.74.68.6f.6e.2d.64.61.74.61.2d.73.74.72.75.63.74.75.72.65.73.2f.62.6c.6f.62.2f.6d.61.73.74.65.72.2f.35.2e.25.32.30.48.65.61.70.2d.62.61.73.65.64.25.32.30.53.74.72.75.63.74.75.72.65.73.2f.68.75.66.66.6d.61.6e.2e.70.79.a.32.2e.20.68.74.74.70.73.3a.2f.2f.67.69.74.68.75.62.2e.63.6f.6d.2f.52.61.52.65.2d.54.65.63.68.6e.6f.6c.6f.67.69.65.73.2f.67.65.6e.73.69.6d.2f.62.6c.6f.62.2f.33.64.35.61.32.31.63.31.63.38.31.32.38.63.62.38.64.64.34.66.36.65.35.31.65.39.65.66.33.64.63.35.61.66.30.30.30.38.37.31.2f.67.65.6e.73.69.6d.2f.6d.6f.64.65.6c.73.2f.64.65.70.72.65.63.61.74.65.64.2f.77.6f.72.64.32.76.65.63.2e.70.79.23.4c.36.37.30.22.a.33.2e.20.68.74.74.70.73.3a.2f.2f.77.77.77.2e.77.69.6b.69.77.61.6e.64.2e.63.6f.6d.2f.65.6e.2f.48.75.66.66.6d.61.6e.5f.63.6f.64.69.6e.67.a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q16: 在gensim中如何实现词向量？ 请将gensim中实现词向量的代码置于答案中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q17: 请说出除了 skip-gram和cbow的其他4中词向量方法的名字， 并且选取其中两个叙述其基本原理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint('a.4f.6e.65.68.6f.74.2c.20.47.6c.6f.76.65.2c.43.6f.76.65.2c.45.4d.4c.6f.a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------- 休息一下，接下来是关于 Keras 和 Tensorflow 使用的 -------------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大家先熟悉一下什么是MNIST数据集： \n",
    "\n",
    "> http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    ">https://en.wikipedia.org/wiki/MNIST_database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q18: 参考keras参考手册，构建一个机器学习模型，该模型能够完成使用DNN(deep neural networks) 实现MNIST数据集的分类；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关键代码: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q19:参考tensorflow的参考手册，构建一个机器学习模型，该模型能够完成使用DNN(deep neural networks)实现MNIST数据集的分类；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关键代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint('68.69.6e.74.73.3a.74.65.6e.73.6f.72.66.6c.6f.77.5b9e.73b0.4d.4e.49.53.54.20.68.74.74.70.73.3a.2f.2f.67.69.74.68.75.62.2e.63.6f.6d.2f.74.65.6e.73.6f.72.66.6c.6f.77.2f.74.65.6e.73.6f.72.66.6c.6f.77.2f.62.6c.6f.62.2f.6d.61.73.74.65.72.2f.74.65.6e.73.6f.72.66.6c.6f.77.2f.65.78.61.6d.70.6c.65.73.2f.75.64.61.63.69.74.79.2f.32.5f.66.75.6c.6c.79.63.6f.6e.6e.65.63.74.65.64.2e.69.70.79.6e.62')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q20: 参考keras和tensorflow对同一问题的实现，说明keras和tensorflow的异同；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q21: tensorflow 使用 Graph 计算机制的优缺点是什么？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q22: Q18， Q19 的tensorflow 或 keras 模型的训练时准确率和测试集准确率分别是多少？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Q23: 训练时准确率大于测试集准确率的现象叫什么名字，在神经网络中如何解决该问题？(至少提出5个解决方法)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Q24: 请使用自己的语言简述通过正则化 (regularization)减小过拟合的原理；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Q25: 在tensorflow官方实例中给出的fully connected 神经网络的分类模型中，数据进行了哪些预处理，这些预处理的原因是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------- 休息一下，接下来是关于 RNN 和 CNN 的 ---------- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q26: 简述CNN的原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q27: CNN的 Spatial Invariant是什么意思？ 是如何做到的？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q28: CNN增加了很多层数，这些层数使用 filter 进行计算。 按说需要拟合的参数变得很多，请问 CNN 是如何解决这个问题的，如何加快速度的？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint('a.6d.61.69.6e.20.70.6f.69.6e.74.73.3a.20.50.6f.6f.6c.69.6e.67.2c.20.50.61.72.61.6d.65.74.65.72.20.53.68.61.72.69.6e.67.a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q29: CNN中的 Batch Normalization有什么意义？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q30: CNN中的 Pooling 起到什么作用？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q31: CNN中的 Fully Connect起到什么作业？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q32: 深度网络中的权值初始化有什么讲究？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading: 参照 Keras 和 Tensorflow 的示例，手敲使用 keras, tensorflow + CNN 实现MNIST分类的问题：\n",
    "\n",
    "+ https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "+ https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/4_convolutions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把代码手敲一遍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q33: 简述RNN解决的问题所具有的特点；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q34: 写出RNN实现时间或者序列相关的数学实现(见课程slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q35: 简述RNN的两种重要变体的提出原因和基本原理？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q36:  Attentional RNN 以及 Stacked RNN 和 Bi-RNN 分别是什么，其做了什么改动？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading 和 CNN 类似，请在 Keras,Tensorflow中查找如何实现 RNN 模型\n",
    "\n",
    "+ https://github.com/Artificial-Intelligence-for-NLP/References/blob/master/AI%20%26%20Machine%20Learning/Hands.On.TensorFlow.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二部分： 项目解决过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "代码主要在 Pycharm 里边写，jupyter 里边写一个关键步骤就行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q37: 要实现文本分类或情感分类，文本信息需要进行哪些初始化操作？自己手工实现，keras提供的API，tenorflow提供的API，分别是哪些？请提供关键代码置于下边`回答`中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hint('id_to_word, word_to_id, padding, batched')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q38 在没有预训练的词向量时候， keras 如何实现embedding操作，即如何依据一个单词的序列获得其向量表示？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q 39: 在**有**预先训练的词向量时候，keras和tensorflow又如何实现embeding操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q40：基于上文进行的数据预处理，使用keras和tensorflow如何构建神经网络模型？请提供关键代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 好的 现在开始切入正题 --\n",
    "\n",
    "其实，我们解决实际问题的时候，很少自己从头到尾写一个神经网络模型，我们往往是找一个效果比较好的类似问题的模型，然后在这个问题上改造。 或者我们在去一个公司的时候，接手的工作也往往是改动以前的模型，所以我们解决这个语义分类问题我们也首先是找一个类似的问题，然后参考一个模型进行修改，变成能够解决我们这个问题的模型。\n",
    "\n",
    "我们以上所以的理论知识，都是用来支持我们做修改，能够看懂别人为何要这样写，然后自己要改哪里。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggle上的“恶意评价识别”这个项目和我们的这个项目是类似的, 大家请首先在这个的 Kernel 里边找到一个公开代码的示例，然后选择一个自己能够看懂且效果较好的模型进行改造。\n",
    "\n",
    "+ https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge\n",
    "+ https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/kernels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle这个问题和我们的问题类似，但是并不是完全一样， 其中最不一样的其实是我们的期望的结果这里, Kaggle 这里的输出是5个类别，然后类别的是0~1直接的数字来预测是否是这个类别，然后我们的客户评价问题中，打标对20个分类的-2, -1, 0, 1四个标记. 一种最简单的方法，是把这个20分类问题变成80分类问题，然后每个分类的输出是0或者1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q41. 依据Kernel 中选择方法，对数据和代码进行改造，使其符合选择该问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q42. 你现在的模型的准确率是多少？ 如何知道你的模型是不是真的学习了 而不是随机的进行猜测？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q43. 你的模型现在准确度不高的原因，你猜测主要是什么？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q43. 如前文所述，这个问题很难，其实现在也没有什么万灵药方法。 所以需要同学们多想想如何有效， 可以给大家参考的优化方式有， 修改vocabulary size, embedding size,去掉停用词，重新组合词组等。 并且结合使用LSTM， GRU， Bi-RNN， Stacked， Attentional, regularization, 等各种方法组合进行模型的优化， 至少进行10次优化，每次优化请按照以下步骤填写："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答：\n",
    "\n",
    "---这是一个实例----\n",
    "\n",
    "第1次优化：\n",
    "\n",
    "1. 存在的问题： loss下降太慢；\n",
    "2. 准备进行的优化：减小模型的神经单元数量；\n",
    "3. 期待的结果：loss下降加快；\n",
    "4. 实际结果：loss下降的确加快(或者并没有加快)\n",
    "5. 原因分析：模型神经元数量减小，收敛需要的次数减少，loss下降加快\n",
    "\n",
    "\n",
    "---你的实验优化结构记录在此---\n",
    "\n",
    "**第1次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第2次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第3次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第4次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第5次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第6次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第7次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第9次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n",
    "\n",
    "**第10次优化**：\n",
    "\n",
    "1. 存在的问题： \n",
    "2. 准备进行的优化：\n",
    "3. 期待的结果：\n",
    "4. 实际结果：\n",
    "5. 原因分析：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最后一步： 使用Flask、Bottle、Bootstrap变成一个网络应用并且部署在服务器上，这样别人就可以直接通过网址访问你的应用啦。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后一步，我们使用Bottle，Bootstrap,Flask等工具进行可视化现实，做出网页能够访问的形式，就像我们的第一个项目一样 😁."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次项目的总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请写项目的总结报告，描述此次项目的主要过程，其中遇到的问题，以及如何解决这些问题的，以及有什么经验和收获。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "恭喜你，你完成了一个**十分**复杂的问题， 能完成这个问题，求是求是，你的能力其实已经达到了国内绝大多数公司的要求，你缺的只是熟练程度。 多多在 Kaggle， 阿里天池里边找一些自己感兴趣的问题，多练习练习。 熟能生巧。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
